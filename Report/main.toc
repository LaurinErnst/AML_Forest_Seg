\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax 
\babel@toc {english}{}
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}% 
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{\numberline {2}Data Preprocessing}{2}{chapter.2}% 
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{\numberline {3}Naive Segmentator + Jaccard?}{3}{chapter.3}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {3.1}Introduction Jaccard Index}{3}{section.3.1}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {3.2}Expected Jaccard Index of a Random Segmentator}{3}{section.3.2}% 
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{\numberline {4}Unet Training}{5}{chapter.4}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {4.1}Overall training procedure}{5}{section.4.1}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {4.2}Choice of Loss functions and optimizers}{5}{section.4.2}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {4.3}Training hyperparameter's}{6}{section.4.3}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {4.3.1}Loss functions}{6}{subsection.4.3.1}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {4.3.2}Optimizer parameters}{6}{subsection.4.3.2}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{Stochastic gradient descent}{6}{subsubsection*.2}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{ADAM}{6}{subsubsection*.3}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {4.3.3}Batch size}{7}{subsection.4.3.3}% 
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{\numberline {5}Training Evaluation}{8}{chapter.5}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {5.1}Mean squared error loss}{8}{section.5.1}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{Stochastic gradient descent}{8}{subsubsection*.4}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{ADAM}{10}{subsubsection*.8}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {5.2}Cross entropy loss}{12}{section.5.2}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{Stochastic gradient descent}{12}{subsubsection*.12}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{ADAM}{14}{subsubsection*.16}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {5.3}SGD compared to ADAM}{17}{section.5.3}% 
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{\numberline {6}SatNet}{18}{chapter.6}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {6.1}Introduction to SatNet}{18}{section.6.1}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {6.2}Training}{20}{section.6.2}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {6.3}Results}{20}{section.6.3}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {6.4}Faulty Data}{20}{section.6.4}% 
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{\numberline {7}Critical Input}{22}{chapter.7}% 
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{\numberline {8}Outlook}{23}{chapter.8}% 
