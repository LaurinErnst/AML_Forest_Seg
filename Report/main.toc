\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax 
\babel@toc {english}{}\relax 
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}%
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{\numberline {2}Data Preprocessing}{2}{chapter.2}%
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{\numberline {3}Naive Segmentator + Jaccard?}{3}{chapter.3}%
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {3.1}Performance measures}{3}{section.3.1}%
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {3.2}Expected Jaccard Index of a Random Segmentator}{4}{section.3.2}%
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {3.3}Segmentation without Neural Networks}{5}{section.3.3}%
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{\numberline {4}Unet Training}{7}{chapter.4}%
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {4.1}Overall training procedure}{7}{section.4.1}%
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {4.2}Choice of Loss functions and optimizers}{7}{section.4.2}%
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {4.3}Training hyperparameter's}{8}{section.4.3}%
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {4.3.1}Loss functions}{8}{subsection.4.3.1}%
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {4.3.2}Optimizer parameters}{8}{subsection.4.3.2}%
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{Stochastic gradient descent}{8}{subsubsection*.3}%
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{ADAM}{8}{subsubsection*.4}%
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {4.3.3}Batch size}{9}{subsection.4.3.3}%
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{\numberline {5}Training Evaluation}{10}{chapter.5}%
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {5.1}Mean squared error loss}{10}{section.5.1}%
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{Stochastic gradient descent}{10}{subsubsection*.5}%
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{ADAM}{12}{subsubsection*.9}%
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {5.2}Cross entropy loss}{14}{section.5.2}%
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{Stochastic gradient descent}{14}{subsubsection*.13}%
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{ADAM}{16}{subsubsection*.17}%
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {5.3}SGD compared to ADAM}{19}{section.5.3}%
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{\numberline {6}SatNet}{20}{chapter.6}%
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {6.1}Introduction to SatNet}{20}{section.6.1}%
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {6.2}Training}{22}{section.6.2}%
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {6.3}Results}{22}{section.6.3}%
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {6.4}Faulty Data}{22}{section.6.4}%
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{\numberline {7}Critical Input}{24}{chapter.7}%
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{\numberline {8}Outlook}{25}{chapter.8}%
