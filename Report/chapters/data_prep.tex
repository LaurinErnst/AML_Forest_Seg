\section{Data Preprocessing}
The dataset from Kaggle consists of 5108 arial forest images and its mask
respectively. They all were in the format 256 x 256. Meaning no image formatting was necessary.
Furthermore the images looked clean, hence we did not need to do
a lot of cleaning of the data.

Each image was saved in the jpg format meaning our
dataset had a size of approximately 185 MB.
Our first intuition was that, since jpg is a
compressed file format, loading jpgs could take longer
than loading from uncompressed files. Thus we tried saving our
data first as json and second as python pickle files.
Both times this lead to a massively inflated dataset of
around 5 GB in size.

When timing dataloading, loading jpgs using pythons
Python Image Library was actually faster than loading jsons
using pandas. Hence our data is loaded from jpeg files.

A big part of our work is our custom dataloader.
It arose from our need for a lot of customizability as it not
only loads data from our custom source but also formats our masks.
 Every mask consists of white pixels with value 255 and black
 pixels with value 0. Trying to make our loss easier to interpret
 we decided to set each white pixel to 1. Since MSE for example would
 the give us a score between 0 and 1 and not a value in the ten thousands.
In the end our dataloader works similar to a standard dataloader
from pytorch for example.
On initialization you set the size of the dataset you want to
use, the set of the trainings set, the batch size you want and
optionally the batch size for the test set
(we used this as we tried our program on different machines thus for
more efficiency it was important to be able to control the batch size
for the test set).

The batch loading itself is done by the function batchloader.
On each new epoch the trainingset is shuffled randomly using numpys
shuffle function. The epoch\_finished function is used to check wether
 the dataset has been completely stepped through and if therefore a new
 epoch has to be started.

<<<<<<< HEAD
Our image data is returned as pytorch tensors respectively containing three arrays for every image one for red one for green and one for blue. Our mask data is returned as a pytorch tensor consisting of only one array per mask containing of zeros and ones.
=======
Our image data is returned as pytorch tensors respectively containing
three arrays for every image one for red one for green and one for blue.
 Our mask data is returned as a pytorch tensor consisting of only one
 array per mask of zeros and ones.
>>>>>>> 4525d948183ac69691793c507720e3f62ad200be

\section{Problems with the Dataset}

When evaluating the training of our models, we looked at the data on which our model performed the worst. One thing that became noticable was the lacking quality of some of the training data as well as some controversial masking.

For example, in \ref{badimg} we can see a satellite image on the left and its given mask on the right; remember that black means no forest. In the image there is one big strip of forest in th south, but the whole image is classified as no forest. This is only one example of images where large chunks of forest are not classified as forest and so make it harder for our neural networks to properly train on the data. It is to be expected that a model either overfits to this faulty data, so that it does get a good score on them but fails to classify to forest, or the model cannot accurately segment this image, because the mask does not fit the picutre.

Some data also classifies large chunks of just ground without any trees as forest. Depending on the size of those chunks, one could argue that it is just a clearing in the forest and thus qualifies as part of the forest. But the more often this appears, the harder it becomes for the networks to tell a clearing in the forest and just a plain field apart. An example of this can be seen in \ref{badimg2}, where the reddish part is what is classified as forest and the only non forest pixels are a small part in the upper right part of the image.

\begin{figure}
  \begin{center}
  \label{badimg}
  \includegraphics[width=.4\linewidth]{images/satellite_images/1_imag}
  \includegraphics[width=.4\linewidth]{images/satellite_images/1_mask}
  \caption{Faulty Data: The mask (left, black means no forest) not matching the given satellite image}
  \end{center}
\end{figure}

\begin{figure}
  \begin{center}
  \label{badimg2}
  \includegraphics[width=.4\linewidth]{images/satellite_images/10_overlap}
  \caption{Controversial Classification: The red part resembles the pixels classified as forest, a lot of brown clearings are classified as forest}
  \end{center}
\end{figure}
