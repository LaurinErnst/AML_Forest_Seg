\section{Performance measures}
In order to evaluate how good our model performs, we need a metric to measure the precision of the predicted masks. 
In the following, $A$ is the set of pixels which are actually forest and $B$ is the set of pixels which our segmentator classified as forest. $Y$ is the set of pixels of the true mask, $\hat{Y}$ the set of predicted pixels. The total number of pixels is $n=256^2$.\\
An obvious approach for comparing the similarity between $A$ and $B$ is the so-called simple matching coefficient \textbf{SMC}. The \textbf{SMC} is given by
\begin{equation}
	\textbf{SMC}:=\frac{|Y\cap \hat{Y}|}{n},
\end{equation} 
so it is simply computed as the proportion of correctly predicted pixels.\\
Though this method might seem easy and intuitive, it has too serious drawbacks to be used as a meaningful performance measurement. The main issue is that forest and non-forest regions are treated symmetrically, even though the goal of our segmentator is only the correct prediction of the forest regions. This aspect is clarified by the following example: 

\begin{figure}[h]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.4\linewidth]{satellite_images/5109_mask.jpg}
		\caption{True mask}
		\label{fig:sub1}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.4\linewidth]{satellite_images/5110_mask.jpg}
		\caption{Prediction}
		\label{fig:sub2}
	\end{subfigure}
	\caption{The gray regions depict forestial, the black regions non-forestial areas. }
	\label{fig:test}
\end{figure}
We assume the left mask shows the true forestial areas, the right mask is the prediction of our model. Clearly, there is no overlap between the forest regions, so $|A \cap B| = 0$, but there is still overlap between the non-forest regions in the centre of the images. Hence, we get $\textbf{SMC}=\frac{128\cdot 256}{256 \cdot 256}=\frac{1}{2}$, even though the forest prediction was completely wrong. This leads to the unpleasant fact that $\textbf{SMC}$ is not really useful for measuring the performance of our prediction.\\

As an alternative, we could change the denominator of the \textbf{SMC} such that we only compute the proportion of correctly predicted pixels in the set of the total (predicted and actual) forestial areas. Thus, we get
\begin{equation}
	J(A, B) := \frac{|A \cap B|}{|A \cup B|},
\end{equation}

which can be rewritten as

\begin{equation}
	J(A, B) = \frac{|A \cap B|}{|A| + |B \setminus A |}.
\end{equation}
This coefficient is very common and known as Jaccard index $J(A,B)$.

\section{Expected Jaccard Index of a Random Segmentator}
To get a better feeling of the Jaccard index, we wanted to calculate the expected index a simple random segmentator gives to compare it to our models. This random segmentator would just assign a $1$ or $0$ with probability $\frac{1}{2}$ to each pixel, where $1$ means forest and $0$ means no forest. Of course, this segmentator does not perform well, but it gives a benchmark for comparison.

Now, let us look at the problem mathematically. Take a arbitrary but fixed satellite image with its mask and define $n$ as the number of pixels it has (for us, that is $256^2$ in every image). Define $m$ as the number of pixels which are forest (meaning they have value 1 in the mask). Obviously, this number is not fixed throughout the images we have, but it is a deterministic constant for every single image.

To define the random segmentator, we define $n$ random variables $X_1, \dots, X_n$ that assign each pixel 0 or 1 with probability $\frac{1}{2}$. Thus,they also have a probability of $\frac{1}{2}$ of assigning the right value for the pixel. Also, each $X_i$ is stochastically independent from the others. This lets us conclude that
\begin{equation}
  X_1, \dots, X_n \overset{\mathrm{iid}}{\sim} \text{Bin}(1, \frac{1}{2})
\end{equation}
where the binomial distribution stands for $X_i$ assigning \textbf{the right value or not} instead of 1 meaning forest and 0 meaning no forest.

If we apply this to the Jaccard index, we first have to look at our sets $A$ and $B$. $A$ is a deterministic set, because the forest pixels in a single image are fixed. This also means that $|A|=m$ per definition. On the other hand, $B$ is the random set of pixels, our segmentator classified as forest. $A \cap B$ is the subset of pixels classified as forest, which truly are forest. Thus,

\begin{equation}
  Y:= |A \cap B| = \sum_{i \in A} X_i
\end{equation}
and because the $X_i$ are i.i.d. and $|A|=m$ we conclude that $Y\sim \text{Bin}(m, \frac{1}{2})$. For $A\setminus B$, we can proceed similarly:
\begin{equation}
  Z:= |A\setminus B| = \sum_{i \notin A} X_i
\end{equation}
and because the $X_i$ are i.i.d. and $|A|=m$ we conclude that $Z\sim \text{Bin}\left (n-m, \frac{1}{2} \right)$. Since $Y$ and $Z$ are independent by definition, we can write
\begin{align*}
  \IE\left(J(A,B)\right) = \ & \IE \left(\frac{Y}{m+Z} \right) \\
   = \ & \IE(Y) \cdot \IE \left(\frac{1}{m+Z} \right)
\end{align*}

With Taylor's theorem, we can approximate
\begin{equation}
  \IE \left(\frac{1}{m+Z}\right) \approx \frac{1}{m+\IE Z}
\end{equation}

and so
\begin{equation}
  \IE(J(A,B)) = \frac{\frac{m}{2}}{m + \frac{n-m}{2}} = \frac{m}{m+n}
\end{equation}

$n$ is a constant throughout the dataset, but $m$ differs for every image. The average of the dataset is $m=40900$, so we can say that our models perform better than guessing if their average Jaccard index is greater than $J = 0.39$ (confirmed by random simulations). We could try to improve the random segmentator by adjusting the guess rate according to the proportion of forest in the dataset, but experiments show that this does not make a big difference in performance.

\section{Segmentation without Neural Networks}
As we have seen in the final project of the lecture "Fundamentals of Machine Learning", rather simple machine learning methods could outperform far more complex structures. Thus, we decided to implement a model that does not rely on neural networks, but uses hand-crafted features instead. \\
The model we created works in the following way:
\begin{enumerate}
	\item Use a common segmentation algorithm to split the satellite image in segments.
	\item For each segment, compute features.
	\item Use a model like logistic regression or a support vector machine to classify each segment as forest or non-forest.
	\item Join all the segments (now consisting of binary data) to obtain a prediction mask.
\end{enumerate}

\textbf{Step 1: Pre-segmentation of images}

In order to segment the satellite images in the first step, we use the Felzenszwalb-Huttenlocher algorithm (Zitat!!!!!!!!!!!!!!!!!!!!). This is a fast graph-based algorithm that has the advantage that it does not tend to "oversegment" plain areas as much as other segmentation algorithms like $k$-means clustering.

\begin{figure}[h]
	\centering
	\includegraphics[width=.8\linewidth]{satellite_images/segments_fz.jpg}
	\caption{Felzenswalb-Huttenlocher segmentation of image 31 in the dataset.}
\end{figure}

\textbf{Step 2: Computing features}

As a second step, we compute the features for each segment we found in the previous step. We could think of three meaningful features that should help identifying forest areas. 

The most obvious one is the color: usually, forest appears to be green. Unfortunately, the color tone is not unique at all. Most of the times, there is a big proportion of blue or red mixed into the color of forest regions, so we couldn't only use the green layer of the RGB satellite image. Instead, we calculated the difference between the averages of the green layer and the other two and chose this value as a feature, so
\begin{equation}
	f_1=2\bar{g}-\bar{r}-\bar{b},
\end{equation}
where $\bar{g}$, $\bar{r}$ and $\bar{b}$ stand for the averages of the respective color values in each segment.

Generally, it can be stated that forest segments are darker than the surrounding areas. By converting the original image to a gray-scale image, we can easily compute the average brightness. We chose this value as our second feature.

By only using color and brightness, it is hard to differentiate between forest and grass regions for example. One feature that might help to decide whether it is a forest or a non-forest region is the standard deviation of the brightness within a segment. Grass regions are typically very smooth, whereas forest shows a larger difference between bright and dark spots due to the many shadows of trees. We observed that it is useful to use apply a Gaussian filter for bluring high frequency noise, because even areas that appear to be flat can have a brightness variation.

\textbf{Step 3: Preparation of the data set and training the models}

For training our models, it is important to have a proper data set. So we split the whole set of images in masks into training and a test set. We used $1500$ for training our models. This seemed to be a sufficiently large number, especially because each image was split again in around $70$ segments, so we got $105,000$ segments overall. Furthermore, each segment had to be labelled in the training data. Thus, we compared the true mask with each segment and if more than 95\% of a segment was covered by forest, we labelled that segment to be a forest region. Additionally, we created a vector consisting of weights which coincide with the logarithm of the segment size, because our model should be better in classifying the bigger segments correctly. We chose to use the logarithm because the sizes of the segments are highly variable and range between 30 up to more than 10,000 pixels. 

We then trained different common classifiers on our training set. Since we have a binary outcome, it was obvious to use logistic regression or a support vector machine, but we tried other methods like random forests and QDA as well. 

\textbf{Step 4: Join the segments}

Our test set consi